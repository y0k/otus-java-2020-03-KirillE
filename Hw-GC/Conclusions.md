Добавляет в каждой итерации заданное количество объектов(loopcounter) в arraylist, спит 20 секунд, 
удаляет первую половину lista, спит 20 сек и т. д., до размера листа = 99% от заданного количества объектов. 
В GC_WH.ods результаты тестов parallelGC, G1 c 
(MaxGCPauseMillis = default/10/100000) с параметрами объема хипа и количества обьектов:
(-Xms256m -Xmx256m loopcounter = 1_000_000) и 
(-Xms2560m -Xmx2560m loopcounter = 10_000_000). 
time — время выполнения из логов. After remove — количество обьектов листа после последнего удаления половины. 
Так же указано количество, время работы сборок и комментарии. Анализ:
	(xmx256): parallelGC выполняется на  1 сек дольше g1 со всеми параметрами. ParallelGC c MaxGc = 10 
выполняется дольше чем с другими параметрами на 0.3 сек, и на 1 мажор сборку больше. 
G1 c MaxGc = 100000 выполняется дольше чем с другими параметрами на 0.2 сек. 
MaxGC 100000 не собирает мусор до 200335ms работы приложения, после 5 минор(245ms, 24, 7, 24 ,7), MacGC 10 — 20 минор(>10ms), 
по сравнению с default 10 минор(9-22ms) при равном времени выполнения. Сумма коротких меньше чем сумма длинных.
Каждую очистку отмечает новых претендентов — чем чаще паузы тем эффективнее следующая из них. 
Баланс latency ~ throughput → увеличение MaxGC влияет негативно на оба показателя. 
	(xmx2560): xms,xmx и loopcounter увеличены в 10 раз. 
ParallelGC во время сна приложения берет все ресурсы, но все равно проигрывает на 2 сек. 
На всех параметрах ведет себя примерно одинаково. 
G1 c MaxGc 100000 выполняется на 2 сек дольше, т. к. опять не спешит собирать мусор, 
первая минор(1957ms) была after remove: 9687500 time: 202535ms. MaxGc default и 
10 примерно одинаковы — 14 минор(70ms) и 15 минор(37-80ms).
	Приложение имитирует потоковую передачу данных, для него важны throughput и latency, 
G1 c default параметрами хипа является оптимальным варинтом, т. к. выигрывает в latency.
